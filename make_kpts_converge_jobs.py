import os
import re
from datetime import datetime


base_dir = '/home/harris.se/converge_test/'
base_py = '/home/harris.se/dft_adsorption/base_pys/bulk_relax.py'
job_file = os.path.join(base_dir, 'run_qe_jobs.sh')
os.makedirs(base_dir, exist_ok=True)

# make files to run CO2 relaxation
kmin = 1
kmax = 8
kpts = [k for k in range(kmin, kmax + 1)]


lines = [f'# Autogenerated {datetime.now()} from {base_py}\n\n']
with open(base_py, 'r') as f:
    for line in f:
        lines.append(line)

# create copies of the python file
pattern = r'kpts\s*=\s*\(\d,\s*\d,\s*\d\)'
for kpt in kpts:
    run_dir = os.path.join(base_dir, f'run{kpt}')
    os.makedirs(run_dir, exist_ok=True)
    fname = os.path.join(run_dir, 'relax.py')
    with open(fname, 'w') as f:
        for line in lines:
            match = re.search(pattern, line)
            if match is None:
                f.write(line)
            else:
                f.write(line.replace(match[0], f'kpts=({kpt}, {kpt}, {kpt})'))

run_i_dir = os.path.join(base_dir, 'run$SLURM_ARRAY_TASK_ID')
# write the array job file
with open(job_file, 'w') as f:
    f.write('#!/bin/bash\n\n')
    f.write('#SBATCH --time=24:00:00\n')
    f.write('#SBATCH --job-name=QE_converge\n')
    f.write('#SBATCH --mem=20Gb\n')
    f.write('#SBATCH --partition=short,west\n')
    f.write(f'#SBATCH --array={kmin}-{kmax}\n\n')
    f.write(f'cd {run_i_dir}\n')
    f.write(f'python relax.py\n')

