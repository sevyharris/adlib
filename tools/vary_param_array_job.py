import os
import re
from datetime import datetime


base_dir = '/work/westgroup/harris.se/espresso/scaling/ecut'
base_py = '/work/westgroup/harris.se/espresso/scaling/ecut/relax.py'
job_file = os.path.join(base_dir, 'run_qe_jobs.sh')
os.makedirs(base_dir, exist_ok=True)

# make files to run CO2 relaxation
ecuts = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]

lines = [f'# Autogenerated {datetime.now()} from {base_py}\n\n']
with open(base_py, 'r') as f:
    for line in f:
        lines.append(line)

# create copies of the python file
pattern_ecutwfc = r"'ecutwfc'\s*:\s*(\d)*"
for i, ecut in enumerate(ecuts):
    run_dir = os.path.join(base_dir, f'run{i}')
    os.makedirs(run_dir, exist_ok=True)
    fname = os.path.join(run_dir, 'relax.py')
    with open(fname, 'w') as f:
        for line in lines:
            match1 = re.search(pattern_ecutwfc, line)
            if match1 is None:
                f.write(line)
            elif match1:
                f.write(line.replace(match1[0], f"'ecutwfc': {ecuts[i]}"))


run_i_dir = os.path.join(base_dir, 'run$SLURM_ARRAY_TASK_ID')
# write the array job file
with open(job_file, 'w') as f:
    f.write('#!/bin/bash\n\n')
    f.write('#SBATCH --time=24:00:00\n')
    f.write('#SBATCH --job-name=scaling_ecut\n')
    f.write('#SBATCH --mem=50Gb\n')
    f.write('#SBATCH --partition=short\n')
    f.write('#SBATCH --constraint=cascadelake\n')
    f.write(f'#SBATCH --array={0}-{len(ecuts) - 1}\n\n')

    f.write('module load gcc/10.1.0\n')
    f.write('module load openmpi/4.0.5-skylake-gcc10.1\n')
    f.write('module load scalapack/2.1.0-skylake\n\n')
    
    f.write(f'cd {run_i_dir}\n')
    f.write(f'python relax.py\n')

